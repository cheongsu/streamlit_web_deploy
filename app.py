# # app.py

# # 1. git clone https://github.com/sce-tts/TTS.git
# # 1-1. TTS -> TTS -> utilsêµ¬ì¡°ì¸ë°, ë‘ë²ˆì§¸ TTSê°€ app.pyì™€ ê°™ì€ ìœ„ì¹˜ì— ì˜¤ë„ë¡ ì„¤ì •
# # 2. git clone https://github.com/sce-tts/g2pK.git


# import streamlit as st
# import pandas as pd
# import numpy as np
# from PIL import Image
# from time import sleep


# from IPython.display import HTML, Audio


# import re
# import sys
# from unicodedata import normalize
# import IPython
# from TTS.utils.synthesizer import Synthesizer

# import streamlit as st
# from bokeh.models.widgets import Button
# from bokeh.models import CustomJS
# from streamlit_bokeh_events import streamlit_bokeh_events


# import streamlit as st
# import librosa
# from pydub import AudioSegment
# import numpy as np
# import io
# import g2pk


# # í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# st.set_page_config(
#     page_icon="ğŸ¶",
#     page_title="ì¹¨ì°©ë§¨ì—°KUì†Œì˜ ìŠ¤íŠ¸ë¦¼ë¦¿",
#     layout="wide",
# )

# # ë²„íŠ¼ ëˆ„ë¥´ê³  ë§í•˜ë©´ ì•Œì•„ì„œ ë©ˆì¶˜ ë’¤ì— input textë¡œ stt ë°˜í™˜í•œë‹¤.
# stt_button = Button(label="Speak", width=100)

# stt_button.js_on_event("button_click", CustomJS(code="""
#     var recognition = new webkitSpeechRecognition();
#     recognition.continuous = true;
#     recognition.interimResults = true;
 
#     recognition.onresult = function (e) {
#         var value = "";
#         for (var i = e.resultIndex; i < e.results.length; ++i) {
#             if (e.results[i].isFinal) {
#                 value += e.results[i][0].transcript;
#             }
#         }
#         if ( value != "") {
#             document.dispatchEvent(new CustomEvent("GET_TEXT", {detail: value}));
#         }
#     }
#     recognition.start();
#     """))

# result = streamlit_bokeh_events(
#     stt_button,
#     events="GET_TEXT",
#     key="listen",
#     refresh_on_update=False,
#     override_height=75,
#     debounce_time=0)

# input_text = ''
# if result:
#     if "GET_TEXT" in result:
#         st.write(result.get("GET_TEXT"))
#         input_text = result.get("GET_TEXT") # micì˜ input


# # ì±—ë´‡ ë“¤ì–´ê°ˆ ìë¦¬


# # íŒŒì¼ ìœ„ì¹˜ ë³€ê²½í•´ì•¼ í•¨!
# synthesizer = Synthesizer(
#     "./glowtts-v2/model_file.pth.tar",
#     "./glowtts-v2/config.json",
#     None,
#     "./hifigan-v2/model_file.pth.tar",
#     "./hifigan-v2/config.json",
#     None,
#     None,
#     False,
# )
# symbols = synthesizer.tts_config.characters.characters

# g2p = g2pk.G2p()

# def normalize_text(text):
#     text = text.strip()

#     for c in ",;:":
#         text = text.replace(c, ".")
#     text = remove_duplicated_punctuations(text)

#     text = jamo_text(text)

#     text = g2p.idioms(text)
#     text = g2pk.english.convert_eng(text, g2p.cmu)
#     text = g2pk.utils.annotate(text, g2p.mecab)
#     text = g2pk.numerals.convert_num(text)
#     text = re.sub("/[PJEB]", "", text)

#     text = alphabet_text(text)

#     # remove unreadable characters
#     text = normalize("NFD", text)
#     text = "".join(c for c in text if c in symbols)
#     text = normalize("NFC", text)

#     text = text.strip()
#     if len(text) == 0:
#         return ""

#     # only single punctuation
#     if text in '.!?':
#         return punctuation_text(text)

#     # append punctuation if there is no punctuation at the end of the text
#     if text[-1] not in '.!?':
#         text += '.'

#     return text


# def remove_duplicated_punctuations(text):
#     text = re.sub(r"[.?!]+\?", "?", text)
#     text = re.sub(r"[.?!]+!", "!", text)
#     text = re.sub(r"[.?!]+\.", ".", text)
#     return text


# def split_text(text):
#     text = remove_duplicated_punctuations(text)

#     texts = []
#     for subtext in re.findall(r'[^.!?\n]*[.!?\n]', text):
#         texts.append(subtext.strip())

#     return texts


# def alphabet_text(text):
#     text = re.sub(r"(a|A)", "ì—ì´", text)
#     text = re.sub(r"(b|B)", "ë¹„", text)
#     text = re.sub(r"(c|C)", "ì”¨", text)
#     text = re.sub(r"(d|D)", "ë””", text)
#     text = re.sub(r"(e|E)", "ì´", text)
#     text = re.sub(r"(f|F)", "ì—í”„", text)
#     text = re.sub(r"(g|G)", "ì¥", text)
#     text = re.sub(r"(h|H)", "ì—ì´ì¹˜", text)
#     text = re.sub(r"(i|I)", "ì•„ì´", text)
#     text = re.sub(r"(j|J)", "ì œì´", text)
#     text = re.sub(r"(k|K)", "ì¼€ì´", text)
#     text = re.sub(r"(l|L)", "ì—˜", text)
#     text = re.sub(r"(m|M)", "ì— ", text)
#     text = re.sub(r"(n|N)", "ì—”", text)
#     text = re.sub(r"(o|O)", "ì˜¤", text)
#     text = re.sub(r"(p|P)", "í”¼", text)
#     text = re.sub(r"(q|Q)", "í", text)
#     text = re.sub(r"(r|R)", "ì•Œ", text)
#     text = re.sub(r"(s|S)", "ì—ìŠ¤", text)
#     text = re.sub(r"(t|T)", "í‹°", text)
#     text = re.sub(r"(u|U)", "ìœ ", text)
#     text = re.sub(r"(v|V)", "ë¸Œì´", text)
#     text = re.sub(r"(w|W)", "ë”ë¸”ìœ ", text)
#     text = re.sub(r"(x|X)", "ì—‘ìŠ¤", text)
#     text = re.sub(r"(y|Y)", "ì™€ì´", text)
#     text = re.sub(r"(z|Z)", "ì§€", text)

#     return text


# def punctuation_text(text):
#     # ë¬¸ì¥ë¶€í˜¸
#     text = re.sub(r"!", "ëŠë‚Œí‘œ", text)
#     text = re.sub(r"\?", "ë¬¼ìŒí‘œ", text)
#     text = re.sub(r"\.", "ë§ˆì¹¨í‘œ", text)

#     return text


# def jamo_text(text):
#     # ê¸°ë³¸ ìëª¨ìŒ
#     text = re.sub(r"ã„±", "ê¸°ì—­", text)
#     text = re.sub(r"ã„´", "ë‹ˆì€", text)
#     text = re.sub(r"ã„·", "ë””ê·¿", text)
#     text = re.sub(r"ã„¹", "ë¦¬ì„", text)
#     text = re.sub(r"ã…", "ë¯¸ìŒ", text)
#     text = re.sub(r"ã…‚", "ë¹„ì", text)
#     text = re.sub(r"ã……", "ì‹œì˜·", text)
#     text = re.sub(r"ã…‡", "ì´ì‘", text)
#     text = re.sub(r"ã…ˆ", "ì§€ì’", text)
#     text = re.sub(r"ã…Š", "ì¹˜ì“", text)
#     text = re.sub(r"ã…‹", "í‚¤ì”", text)
#     text = re.sub(r"ã…Œ", "í‹°ì•", text)
#     text = re.sub(r"ã…", "í”¼ì–", text)
#     text = re.sub(r"ã…", "íˆì—", text)
#     text = re.sub(r"ã„²", "ìŒê¸°ì—­", text)
#     text = re.sub(r"ã„¸", "ìŒë””ê·¿", text)
#     text = re.sub(r"ã…ƒ", "ìŒë¹„ì", text)
#     text = re.sub(r"ã…†", "ìŒì‹œì˜·", text)
#     text = re.sub(r"ã…‰", "ìŒì§€ì’", text)
#     text = re.sub(r"ã„³", "ê¸°ì—­ì‹œì˜·", text)
#     text = re.sub(r"ã„µ", "ë‹ˆì€ì§€ì’", text)
#     text = re.sub(r"ã„¶", "ë‹ˆì€íˆì—", text)
#     text = re.sub(r"ã„º", "ë¦¬ì„ê¸°ì—­", text)
#     text = re.sub(r"ã„»", "ë¦¬ì„ë¯¸ìŒ", text)
#     text = re.sub(r"ã„¼", "ë¦¬ì„ë¹„ì", text)
#     text = re.sub(r"ã„½", "ë¦¬ì„ì‹œì˜·", text)
#     text = re.sub(r"ã„¾", "ë¦¬ì„í‹°ì•", text)
#     text = re.sub(r"ã„¿", "ë¦¬ì„í”¼ì", text)
#     text = re.sub(r"ã…€", "ë¦¬ì„íˆì—", text)
#     text = re.sub(r"ã…„", "ë¹„ìì‹œì˜·", text)
#     text = re.sub(r"ã…", "ì•„", text)
#     text = re.sub(r"ã…‘", "ì•¼", text)
#     text = re.sub(r"ã…“", "ì–´", text)
#     text = re.sub(r"ã…•", "ì—¬", text)
#     text = re.sub(r"ã…—", "ì˜¤", text)
#     text = re.sub(r"ã…›", "ìš”", text)
#     text = re.sub(r"ã…œ", "ìš°", text)
#     text = re.sub(r"ã… ", "ìœ ", text)
#     text = re.sub(r"ã…¡", "ìœ¼", text)
#     text = re.sub(r"ã…£", "ì´", text)
#     text = re.sub(r"ã…", "ì• ", text)
#     text = re.sub(r"ã…’", "ì–˜", text)
#     text = re.sub(r"ã…”", "ì—", text)
#     text = re.sub(r"ã…–", "ì˜ˆ", text)
#     text = re.sub(r"ã…˜", "ì™€", text)
#     text = re.sub(r"ã…™", "ì™œ", text)
#     text = re.sub(r"ã…š", "ì™¸", text)
#     text = re.sub(r"ã…", "ì›Œ", text)
#     text = re.sub(r"ã…", "ì›¨", text)
#     text = re.sub(r"ã…Ÿ", "ìœ„", text)
#     text = re.sub(r"ã…¢", "ì˜", text)

#     return text

# def normalize_multiline_text(long_text):
#     texts = split_text(long_text)
#     normalized_texts = [normalize_text(text).strip() for text in texts]
#     return [text for text in normalized_texts if len(text) > 0]

# def synthesize(text):
#     wavs = synthesizer.tts(text, None, None)
#     return wavs

# # def wav_to_bytes(wav_array, sample_rate=22050):
# #     audio_segment = AudioSegment(
# #         wav_array.tobytes(),
# #         frame_rate=sample_rate,
# #         sample_width=wav_array.dtype.itemsize, 
# #         channels=1
# #     )
# #     byte_io = io.BytesIO()
# #     audio_segment.export(byte_io, format="wav")
# #     byte_wav = byte_io.getvalue()
# #     byte_io.close()
# #     return byte_wav

# # for text in normalize_multiline_text(input_text):
# #     wav = synthesizer.tts(text, None, None)

# #     #IPython.display.display(IPython.display.Audio(wav, rate=22050))
# #     st.audio(wav, format="audio/wav",sample_rate =22050 )
#     # ë²„ì „ ë¬¸ì œ ë°œìƒ
#     # st.audioë§Œ í™•ì¸í•´ë³´ë©´ ë ë“¯. wavì— nuarrayí˜•íƒœê°€ ë“¤ì–´ê°€ì•¼ í•¨.

# # textë¥¼ í†µí•´ wavê°€ ìƒì„±ëì„ ë•Œ wavë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆëŠ” streamlit í•¨ìˆ˜ë§Œ ë„£ìœ¼ë©´ ë¨.

# from io import BytesIO
# from scipy.io.wavfile import write

# sample_text = "ì•ˆë…•í•˜ì„¸ìš”"

# for text in normalize_multiline_text(sample_text):
#     wav = synthesizer.tts(text, None, None)
#     type(wav)
#     IPython.display.display(IPython.display.Audio(wav, rate=22050))
#     wav_norm = np.int16(wav/np.max(np.abs(wav)) * 32767)
#     virtual_file = BytesIO()
#     write(virtual_file, 22050, wav_norm)
#     virtual_file.seek(0)
#     st.audio(virtual_file.read(), format = 'audio/wav')

# # ë¬¸ì œì  - mic - input_textê°€ ì•ˆë¨. 

# import streamlit as st
# from bokeh.models.widgets import Button
# from bokeh.models import CustomJS

# text = st.text_input("Say what ?")

# tts_button = Button(label="Speak", width=100)

# tts_button.js_on_event("button_click", CustomJS(code=f"""
#     var u = new SpeechSynthesisUtterance();
#     u.text = "{text}";
#     u.lang = 'en-US';

#     speechSynthesis.speak(u);
#     """))
# st.bokeh_chart(tts_button)

# app.py

# import streamlit as st
# import pandas as pd
# import numpy as np
# from PIL import Image
# from time import sleep


# # í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# st.set_page_config(
#     page_icon="ğŸ¶",
#     page_title="ë¹…ê³µì¼ì˜ ìŠ¤íŠ¸ë¦¼ë¦¿ ë°°í¬í•˜ê¸°",
#     layout="wide",
# )

# # ë¡œë”©ë°” êµ¬í˜„í•˜ê¸°
# with st.spinner(text="í˜ì´ì§€ ë¡œë”©ì¤‘..."):
#     sleep(2)

# # í˜ì´ì§€ í—¤ë”, ì„œë¸Œí—¤ë” ì œëª© ì„¤ì •
# st.header("ë¹…ê³µì¼ í˜ì´ì§€ì— ì˜¤ì‹ ê±¸ í™˜ì˜í•©ë‹ˆë‹¤ğŸ‘‹")
# st.subheader("ìŠ¤íŠ¸ë¦¼ë¦¿ ê¸°ëŠ¥ ë§›ë³´ê¸°")

# # í˜ì´ì§€ ì»¬ëŸ¼ ë¶„í• (ì˜ˆ: ë¶€íŠ¸ìŠ¤íŠ¸ë© ì»¬ëŸ¼, ê·¸ë¦¬ë“œ)
# cols = st.columns((1, 1, 2))
# cols[0].metric("10/11", "15 Â°C", "2")
# cols[0].metric("10/12", "17 Â°C", "2 Â°F")
# cols[0].metric("10/13", "15 Â°C", "2")
# cols[1].metric("10/14", "17 Â°C", "2 Â°F")
# cols[1].metric("10/15", "14 Â°C", "-3 Â°F")
# cols[1].metric("10/16", "13 Â°C", "-1 Â°F")

# # ë¼ì¸ ê·¸ë˜í”„ ë°ì´í„° ìƒì„±(with. Pandas)
# chart_data = pd.DataFrame(
#     np.random.randn(20, 3),
#     columns=['a', 'b', 'c'])

# # ì»¬ëŸ¼ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì— ë¼ì¸ì°¨íŠ¸ ìƒì„±
# cols[2].line_chart(chart_data)


import streamlit as st
from bokeh.models.widgets import Button
from bokeh.models import CustomJS
from streamlit_bokeh_events import streamlit_bokeh_events

stt_button = Button(label="Speak", width=100)

stt_button.js_on_event("button_click", CustomJS(code="""
    var recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = function (e) {
        var value = "";
        for (var i = e.resultIndex; i < e.results.length; ++i) {
            if (e.results[i].isFinal) {
                value += e.results[i][0].transcript;
            }
        }
        if ( value != "") {
            document.dispatchEvent(new CustomEvent("GET_TEXT", {detail: value}));
        }
    }
    recognition.start();
    """))

result = streamlit_bokeh_events(
    stt_button,
    events="GET_TEXT",
    key="listen",
    refresh_on_update=False,
    override_height=75,
    debounce_time=0)

if result:
    if "GET_TEXT" in result:
        st.write(result.get("GET_TEXT"))
